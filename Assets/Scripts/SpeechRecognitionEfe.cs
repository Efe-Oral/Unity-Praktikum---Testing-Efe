using System;
using System.Threading.Tasks;
using UnityEngine;
using TMPro;
using Microsoft.CognitiveServices.Speech;
using Microsoft.CognitiveServices.Speech.Audio;

public class SpeechRecognitionEfe : MonoBehaviour
{
    [SerializeField] private TextMeshProUGUI inputField;  // üîµ Assign in Unity Inspector

    [SerializeField] private AudioClip startSound;  // üéµ Sound for when recognition starts
    [SerializeField] private AudioClip endSound;    // üéµ Sound for when recognition ends
    private AudioSource audioSource;

    private static string speechKey = "DuTF9airVdsZZpxpgaQBj0TgJbQtkxGW22Cwrb014SyboVhXoziOJQQJ99BCACPV0roXJ3w3AAAYACOGBSBH";
    private static string speechRegion = "germanywestcentral";

    private OllamaAPIClient ollamaClient;  // Reference to OllamaAPIClient

    void Start()
    {
        // üéµ Get or Add an AudioSource to the GameObject
        audioSource = GetComponent<AudioSource>();
        if (audioSource == null)
        {
            audioSource = gameObject.AddComponent<AudioSource>();
        }

        // üî¥ Find the OllamaAPIClient in the scene
        ollamaClient = FindObjectOfType<OllamaAPIClient>();

        if (ollamaClient == null)
        {
            Debug.LogError("‚ùå OllamaAPIClient not found in the scene! Make sure it's attached to a GameObject.");
        }
    }

    void Update()
    {
        if (Input.GetKeyDown(KeyCode.Space))  // üî¥ Press "Space" to activate speech recognition
        {
            Debug.Log("üé§ Space key pressed! Starting speech recognition...");
            PlaySound(startSound);  // üîä Play start sound
            _ = RecognizeSpeechAsync();
        }
    }

    private async Task RecognizeSpeechAsync()
    {
        var speechConfig = SpeechConfig.FromSubscription(speechKey, speechRegion);
        speechConfig.SpeechRecognitionLanguage = "en-US";

        using var audioConfig = AudioConfig.FromDefaultMicrophoneInput();
        using var speechRecognizer = new SpeechRecognizer(speechConfig, audioConfig);

        Debug.Log("üé§ Listening for speech...");
        var result = await speechRecognizer.RecognizeOnceAsync();

        PlaySound(endSound);  // üîä Play end sound
        ProcessSpeechResult(result);
    }

    private void ProcessSpeechResult(SpeechRecognitionResult result)
    {
        if (result.Reason == ResultReason.RecognizedSpeech)
        {
            Debug.Log($"‚úÖ Recognized: {result.Text}");
            if (inputField != null)
            {
                inputField.text = result.Text;  // üîµ Update Unity InputField with recognized text
            }

            // üî¥ Trigger conversation in OllamaAPIClient
            if (ollamaClient != null)
            {
                if (ollamaClient.isProcessing)
                {
                    Debug.Log("‚ö†Ô∏è A response is still being processed. Please wait.");
                    return;
                }
                Debug.Log("üí¨ Starting conversation with recognized speech...");
                ollamaClient.StartConversation();
            }
        }
        else
        {
            Debug.Log("‚ö†Ô∏è Speech not recognized.");
        }
    }

    // üéµ Method to play a sound effect
    private void PlaySound(AudioClip clip)
    {
        if (clip != null && audioSource != null)
        {
            audioSource.PlayOneShot(clip);
        }
    }
}
